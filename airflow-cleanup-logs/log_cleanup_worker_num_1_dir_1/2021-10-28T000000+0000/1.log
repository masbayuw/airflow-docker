[2021-10-30 12:57:00,146] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: airflow-cleanup-logs.log_cleanup_worker_num_1_dir_1 2021-10-28T00:00:00+00:00 [queued]>
[2021-10-30 12:57:00,401] {taskinstance.py:851} INFO - Dependencies all met for <TaskInstance: airflow-cleanup-logs.log_cleanup_worker_num_1_dir_1 2021-10-28T00:00:00+00:00 [queued]>
[2021-10-30 12:57:00,411] {taskinstance.py:1042} INFO - 
--------------------------------------------------------------------------------
[2021-10-30 12:57:00,412] {taskinstance.py:1043} INFO - Starting attempt 1 of 2
[2021-10-30 12:57:00,412] {taskinstance.py:1044} INFO - 
--------------------------------------------------------------------------------
[2021-10-30 12:57:00,467] {taskinstance.py:1063} INFO - Executing <Task(BashOperator): log_cleanup_worker_num_1_dir_1> on 2021-10-28T00:00:00+00:00
[2021-10-30 12:57:00,486] {standard_task_runner.py:52} INFO - Started process 171 to run task
[2021-10-30 12:57:00,524] {standard_task_runner.py:76} INFO - Running: ['airflow', 'tasks', 'run', 'airflow-cleanup-logs', 'log_cleanup_worker_num_1_dir_1', '2021-10-28T00:00:00+00:00', '--job-id', '41627', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/airflow-cleanup-logs.py', '--cfg-path', '/tmp/tmpevospb53', '--error-file', '/tmp/tmp3r9ty7h2']
[2021-10-30 12:57:00,530] {standard_task_runner.py:77} INFO - Job 41627: Subtask log_cleanup_worker_num_1_dir_1
[2021-10-30 12:57:00,757] {logging_mixin.py:104} INFO - Running <TaskInstance: airflow-cleanup-logs.log_cleanup_worker_num_1_dir_1 2021-10-28T00:00:00+00:00 [running]> on host f8e9f518f089
[2021-10-30 12:57:01,055] {taskinstance.py:1257} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=bwiratmo91@gmail.com
AIRFLOW_CTX_DAG_OWNER=bayu
AIRFLOW_CTX_DAG_ID=airflow-cleanup-logs
AIRFLOW_CTX_TASK_ID=log_cleanup_worker_num_1_dir_1
AIRFLOW_CTX_EXECUTION_DATE=2021-10-28T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-10-28T00:00:00+00:00
[2021-10-30 12:57:01,058] {bash.py:135} INFO - Tmp dir root location: 
 /tmp
[2021-10-30 12:57:01,061] {bash.py:158} INFO - Running command: 

echo "Getting Configurations..."
BASE_LOG_FOLDER="/opt/airflow/logs/scheduler"
WORKER_SLEEP_TIME="3"

sleep ${WORKER_SLEEP_TIME}s

MAX_LOG_AGE_IN_DAYS=""
if [ "${MAX_LOG_AGE_IN_DAYS}" == "" ]; then
    echo "maxLogAgeInDays conf variable isn't included. Using Default '0'."
    MAX_LOG_AGE_IN_DAYS='0'
fi
ENABLE_DELETE=true
echo "Finished Getting Configurations"
echo ""

echo "Configurations:"
echo "BASE_LOG_FOLDER:      '${BASE_LOG_FOLDER}'"
echo "MAX_LOG_AGE_IN_DAYS:  '${MAX_LOG_AGE_IN_DAYS}'"
echo "ENABLE_DELETE:        '${ENABLE_DELETE}'"

cleanup() {
    echo "Executing Find Statement: $1"
    FILES_MARKED_FOR_DELETE=`eval $1`
    echo "Process will be Deleting the following File(s)/Directory(s):"
    echo "${FILES_MARKED_FOR_DELETE}"
    echo "Process will be Deleting `echo "${FILES_MARKED_FOR_DELETE}" |     grep -v '^$' | wc -l` File(s)/Directory(s)"         # "grep -v '^$'" - removes empty lines.
    # "wc -l" - Counts the number of lines
    echo ""
    if [ "${ENABLE_DELETE}" == "true" ];
    then
        if [ "${FILES_MARKED_FOR_DELETE}" != "" ];
        then
            echo "Executing Delete Statement: $2"
            eval $2
            DELETE_STMT_EXIT_CODE=$?
            if [ "${DELETE_STMT_EXIT_CODE}" != "0" ]; then
                echo "Delete process failed with exit code                     '${DELETE_STMT_EXIT_CODE}'"

                echo "Removing lock file..."
                rm -f /tmp/airflow_log_cleanup_worker.lock
                if [ "${REMOVE_LOCK_FILE_EXIT_CODE}" != "0" ]; then
                    echo "Error removing the lock file.                     Check file permissions.                    To re-run the DAG, ensure that the lock file has been                     deleted (/tmp/airflow_log_cleanup_worker.lock)."
                    exit ${REMOVE_LOCK_FILE_EXIT_CODE}
                fi
                exit ${DELETE_STMT_EXIT_CODE}
            fi
        else
            echo "WARN: No File(s)/Directory(s) to Delete"
        fi
    else
        echo "WARN: You're opted to skip deleting the File(s)/Directory(s)!!!"
    fi
}


if [ ! -f /tmp/airflow_log_cleanup_worker.lock ]; then

    echo "Lock file not found on this node!     Creating it to prevent collisions..."
    touch /tmp/airflow_log_cleanup_worker.lock
    CREATE_LOCK_FILE_EXIT_CODE=$?
    if [ "${CREATE_LOCK_FILE_EXIT_CODE}" != "0" ]; then
        echo "Error creating the lock file.         Check if the airflow user can create files under tmp directory.         Exiting..."
        exit ${CREATE_LOCK_FILE_EXIT_CODE}
    fi

    echo ""
    echo "Running Cleanup Process..."

    FIND_STATEMENT="find ${BASE_LOG_FOLDER}/*/* -type f -mtime      +${MAX_LOG_AGE_IN_DAYS}"
    DELETE_STMT="${FIND_STATEMENT} -exec rm -f {} \;"

    cleanup "${FIND_STATEMENT}" "${DELETE_STMT}"
    CLEANUP_EXIT_CODE=$?

    FIND_STATEMENT="find ${BASE_LOG_FOLDER}/*/* -type d -empty"
    DELETE_STMT="${FIND_STATEMENT} -prune -exec rm -rf {} \;"

    cleanup "${FIND_STATEMENT}" "${DELETE_STMT}"
    CLEANUP_EXIT_CODE=$?

    FIND_STATEMENT="find ${BASE_LOG_FOLDER}/* -type d -empty"
    DELETE_STMT="${FIND_STATEMENT} -prune -exec rm -rf {} \;"

    cleanup "${FIND_STATEMENT}" "${DELETE_STMT}"
    CLEANUP_EXIT_CODE=$?

    echo "Finished Running Cleanup Process"

    echo "Deleting lock file..."
    rm -f /tmp/airflow_log_cleanup_worker.lock
    REMOVE_LOCK_FILE_EXIT_CODE=$?
    if [ "${REMOVE_LOCK_FILE_EXIT_CODE}" != "0" ]; then
        echo "Error removing the lock file. Check file permissions. To re-run the DAG, ensure that the lock file has been deleted (/tmp/airflow_log_cleanup_worker.lock)."
        exit ${REMOVE_LOCK_FILE_EXIT_CODE}
    fi

else
    echo "Another task is already deleting logs on this worker node.     Skipping it!"
    echo "If you believe you're receiving this message in error, kindly check     if /tmp/airflow_log_cleanup_worker.lock exists and delete it."
    exit 0
fi

[2021-10-30 12:57:01,100] {bash.py:169} INFO - Output:
[2021-10-30 12:57:01,102] {bash.py:173} INFO - Getting Configurations...
[2021-10-30 12:57:04,113] {bash.py:173} INFO - maxLogAgeInDays conf variable isn't included. Using Default '0'.
[2021-10-30 12:57:04,126] {bash.py:173} INFO - Finished Getting Configurations
[2021-10-30 12:57:04,127] {bash.py:173} INFO - 
[2021-10-30 12:57:04,127] {bash.py:173} INFO - Configurations:
[2021-10-30 12:57:04,127] {bash.py:173} INFO - BASE_LOG_FOLDER:      '/opt/airflow/logs/scheduler'
[2021-10-30 12:57:04,127] {bash.py:173} INFO - MAX_LOG_AGE_IN_DAYS:  '0'
[2021-10-30 12:57:04,128] {bash.py:173} INFO - ENABLE_DELETE:        'true'
[2021-10-30 12:57:04,128] {bash.py:173} INFO - Another task is already deleting logs on this worker node.     Skipping it!
[2021-10-30 12:57:04,128] {bash.py:173} INFO - If you believe you're receiving this message in error, kindly check     if /tmp/airflow_log_cleanup_worker.lock exists and delete it.
[2021-10-30 12:57:04,128] {bash.py:177} INFO - Command exited with return code 0
[2021-10-30 12:57:04,574] {taskinstance.py:1166} INFO - Marking task as SUCCESS. dag_id=airflow-cleanup-logs, task_id=log_cleanup_worker_num_1_dir_1, execution_date=20211028T000000, start_date=20211030T125700, end_date=20211030T125704
[2021-10-30 12:57:04,890] {taskinstance.py:1220} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2021-10-30 12:57:04,976] {local_task_job.py:146} INFO - Task exited with return code 0
